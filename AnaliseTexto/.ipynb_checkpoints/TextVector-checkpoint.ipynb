{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "e4c7d791-d39c-4247-a950-8f541b2b2b2b"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Classificação de textos com *scikit-learn*\n",
    "por Prof. Sanderson Macedo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "918ce0e7-8f69-4d3c-8106-d3c5264c94e3"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<hr size=30>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "ca5fe97a-0224-4915-a59d-38e6baa218a2"
    }
   },
   "source": [
    "## Agenda\n",
    "\n",
    "\n",
    "1. Representar um texto como dados numéricos\n",
    "2. Ler o *dataset* de texto no Pandas\n",
    "2. Vetorizar nossso *dataset*\n",
    "4. Construir e avaliar um modelo\n",
    "5. Comparar modelos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "d2e20804-da18-483c-bd40-8c25e2d4699c"
    }
   },
   "outputs": [],
   "source": [
    "##Importando pandas e numpy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "76e5a32a-69c4-4dc5-a66b-23d2cca623af"
    }
   },
   "source": [
    "## 1. Definindo um vetor de textos \n",
    "Os textos do vetor podem ser adquiridos por meio da leitura de \n",
    "pdf's, doc's, twitter's... etc.\n",
    "\n",
    "Esses textos serão a base de treinamento\n",
    "para a classificação do sentimento de um novo texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "56bab267-0993-4d7a-9436-11bc5de3d1d3"
    }
   },
   "outputs": [],
   "source": [
    "train = [\n",
    "    'Eu te amo e não existe nada melhor que você',\n",
    "    'Você é algo assim... é tudo pra mim. Ao meu amor... Amor!',\n",
    "    'Eu te odeio muito, você não presta!',\n",
    "    'Não gosto de você'\n",
    "    \n",
    "   ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "fc1fc669-a603-412e-8855-837d750718ff"
    }
   },
   "source": [
    "## 2. Definindo um vetor de sentimentos\n",
    "Criaremos um vetor de sentimentos chamado **_felling_**. \n",
    "\n",
    "Cada posição do vetor **_felling_** representa o sentimento **BOM** (1) ou **RUIM** (0) para os textos que passamos ao vetor **_train_**.\n",
    "\n",
    "Por exemplo: a frase da primeira posição do vetor **_train_**:\n",
    "\n",
    "> 'Eu te amo e não existe nada melhor que você'\n",
    "\n",
    "Foi classificada como sendo um texto **BOM**:\n",
    "\n",
    "> 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "68a4277e-e38c-42ac-8528-0b90efe86e42"
    }
   },
   "outputs": [],
   "source": [
    "felling = [1,1,0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "f43ff54a-e843-4a35-8447-66665f36ebca"
    }
   },
   "source": [
    "## 3. Análise de texto com _scikit-learn_.\n",
    "\n",
    "Texto de [scikit-learn documentation](http://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction):\n",
    "\n",
    "> Análise de texto é um campo de aplicação importante para algoritmos de aprendizado de máquina. No entanto, uma sequência de símbolos não podem ser passada diretamente aos algoritmos de Machine Learning, pois a maioria deles espera vetores de características numéricas com um tamanho fixo, em vez de documentos de texto com comprimento variável.\n",
    "\n",
    "Mas nesse caso podemos realizar algumas transformações de para poder manipular textos em algoritmos de aprendizagem.\n",
    "\n",
    "Portanto, aqui utilizaremos a [CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)\n",
    "para converter textos em uma matriz que expressará a quantidade \"tokens\" dos textos.\n",
    "\n",
    "Importamos a classe e criamos uma instância chamada **_vect_**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "1ada59d7-f1ba-4625-8999-b8af5aaf461c"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "154ef867-0532-45ad-9910-c87f6711d1b0"
    }
   },
   "source": [
    "## 4. Treinamento criando o dicionário.\n",
    "Agora treinamos o algoritmo com o vetor de textos que criamos acima. Chamamos o método **_fit()_** passando o vetor de textos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "eff3a289-8c0d-4374-9400-d988a6b36624"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veja que o parametro *analyzer* é defindo por padrão como *'word'* na classe *CountVectorizer*. Isso signicica que a classe ignora palavras com menos de dois (2) caracteres e pontuações. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "d4093cdd-6b19-4fed-9a01-5ee02f41ca51"
    }
   },
   "source": [
    "## 5. Nosso dicionário\n",
    "Aqui vamos listar de forma única\n",
    "quais palavras forma utilizadas no texto, formando assim um dicionário de palavras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "3ab9a844-7f38-40c5-a57f-4a2fbf3343ba"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['algo',\n",
       " 'amo',\n",
       " 'amor',\n",
       " 'ao',\n",
       " 'assim',\n",
       " 'de',\n",
       " 'eu',\n",
       " 'existe',\n",
       " 'gosto',\n",
       " 'melhor',\n",
       " 'meu',\n",
       " 'mim',\n",
       " 'muito',\n",
       " 'nada',\n",
       " 'não',\n",
       " 'odeio',\n",
       " 'pra',\n",
       " 'presta',\n",
       " 'que',\n",
       " 'te',\n",
       " 'tudo',\n",
       " 'você']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## examinando o dicionário criado em ordem alfabética.\n",
    "vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Transformação em matriz esparsa em relação as frases\n",
    "Essa transformação é importante porque cria uma matriz onde:\n",
    "\n",
    "1. Cada linha representa um texto do vetor **_train_** \n",
    "2. Cada coluna uma palavra do dicionário aprendido.\n",
    "3. Se a palavra ocorrer no texto o valor será 1 caso contrário 0.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "34cfd603-24de-4379-9a69-353ba0e50fba"
    }
   },
   "outputs": [],
   "source": [
    "simple_train_dtm = vect.transform(text)\n",
    "ocorrencias = simple_train_dtm.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "88fe39dd-0355-4dd7-b9d6-ed668225208d"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1],\n",
       "       [1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ocorrencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "2e563c0f-37c5-4861-85c6-9185c20e3507"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algo</th>\n",
       "      <th>amo</th>\n",
       "      <th>assim</th>\n",
       "      <th>eu</th>\n",
       "      <th>existe</th>\n",
       "      <th>melhor</th>\n",
       "      <th>mim</th>\n",
       "      <th>muito</th>\n",
       "      <th>nada</th>\n",
       "      <th>não</th>\n",
       "      <th>odeio</th>\n",
       "      <th>pra</th>\n",
       "      <th>presta</th>\n",
       "      <th>que</th>\n",
       "      <th>te</th>\n",
       "      <th>tudo</th>\n",
       "      <th>você</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   algo  amo  assim  eu  existe  melhor  mim  muito  nada  não  odeio  pra  \\\n",
       "0     0    1      0   1       1       1    0      0     1    1      0    0   \n",
       "1     1    0      1   0       0       0    1      0     0    0      0    1   \n",
       "2     0    0      0   1       0       0    0      1     0    1      1    0   \n",
       "\n",
       "   presta  que  te  tudo  você  \n",
       "0       0    1   1     0     1  \n",
       "1       0    0   0     1     1  \n",
       "2       1    0   1     0     1  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(simple_train_dtm.toarray(), columns=vect.get_feature_names())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "d30743bf-e9b2-46ba-93bd-0615c79b1b29"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(simple_train_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "95d91cb6-e3f8-4b4b-ab82-900f8719f4db"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1)\t1\n",
      "  (0, 3)\t1\n",
      "  (0, 4)\t1\n",
      "  (0, 5)\t1\n",
      "  (0, 8)\t1\n",
      "  (0, 9)\t1\n",
      "  (0, 13)\t1\n",
      "  (0, 14)\t1\n",
      "  (0, 16)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 2)\t1\n",
      "  (1, 6)\t1\n",
      "  (1, 11)\t1\n",
      "  (1, 15)\t1\n",
      "  (1, 16)\t1\n",
      "  (2, 3)\t1\n",
      "  (2, 7)\t1\n",
      "  (2, 9)\t1\n",
      "  (2, 10)\t1\n",
      "  (2, 12)\t1\n",
      "  (2, 14)\t1\n",
      "  (2, 16)\t1\n"
     ]
    }
   ],
   "source": [
    "print(simple_train_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "201b01cf-47f9-4a94-baf5-9270271e053e"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
